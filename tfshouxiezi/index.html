<!-- build time:Mon Nov 18 2019 20:42:43 GMT+0800 (GMT+08:00) --><!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><!DOCTYPE html> <html lang="zh-Hans"> <head><meta name="generator" content="Hexo 3.9.0"> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><!--[if lt IE 9]> <style>body {display: none; background: none !important} </style> <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" /> <![endif]--><!-- rebuild by neat --> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1"> <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"> <meta name="format-detection" content="telephone=no"> <meta name="author" content="Porter Pan"> <meta name="description" content="摘要本节主要是学习TensorFlow的相关学习笔记，主要是基础的学习路线，包括简单的实例笔记等。 内容包括如下：  部分数学推导 部分代码实现 MNIST手写数字识别的模型训练过程 MNIST手写数字识别的模型测试过程 MNIST手写数字是别的模型应用   提示本部分是一个PDF手稿，暂时未整理排版，只能在电脑端预览本部分的PDF笔记,手机上的PDF笔记将不会显示出来。    Edit By P"> <meta name="keywords" content="Deep Learning,TensorFlow"> <meta property="og:type" content="article"> <meta property="og:title" content="第五章 TensorFlow MNIST 手写字识别笔记"> <meta property="og:url" content="https://blogs.porterpan.top/tfshouxiezi/index.html"> <meta property="og:site_name" content="Porter-聚水渊"> <meta property="og:description" content="摘要本节主要是学习TensorFlow的相关学习笔记，主要是基础的学习路线，包括简单的实例笔记等。 内容包括如下：  部分数学推导 部分代码实现 MNIST手写数字识别的模型训练过程 MNIST手写数字识别的模型测试过程 MNIST手写数字是别的模型应用   提示本部分是一个PDF手稿，暂时未整理排版，只能在电脑端预览本部分的PDF笔记,手机上的PDF笔记将不会显示出来。    Edit By P"> <meta property="og:locale" content="zh-Hans"> <meta property="og:image" content="https://s2.ax1x.com/2019/07/31/etxrBn.png"> <meta property="og:image" content="https://s2.ax1x.com/2019/07/31/etxfc4.png"> <meta property="og:image" content="https://s2.ax1x.com/2019/06/07/VwajeO.md.png"> <meta property="og:image" content="https://s2.ax1x.com/2019/06/07/Vw10Zn.png"> <meta property="og:updated_time" content="2019-09-16T13:26:47.522Z"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="第五章 TensorFlow MNIST 手写字识别笔记"> <meta name="twitter:description" content="摘要本节主要是学习TensorFlow的相关学习笔记，主要是基础的学习路线，包括简单的实例笔记等。 内容包括如下：  部分数学推导 部分代码实现 MNIST手写数字识别的模型训练过程 MNIST手写数字识别的模型测试过程 MNIST手写数字是别的模型应用   提示本部分是一个PDF手稿，暂时未整理排版，只能在电脑端预览本部分的PDF笔记,手机上的PDF笔记将不会显示出来。    Edit By P"> <meta name="twitter:image" content="https://s2.ax1x.com/2019/07/31/etxrBn.png"> <link rel="apple-touch-icon" href="/apple-touch-icon.png"> <link rel="alternate" href="/atom.xml" title="Porter-聚水渊" type="application/atom+xml"> <link rel="shortcut icon" href="/favicon.png"> <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet"> <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet"> <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script> <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet"> <link rel="stylesheet" href="/css/style.css"> <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet"> <title>第五章 TensorFlow MNIST 手写字识别笔记 | Porter-聚水渊</title> <script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script> <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script> <script> var yiliaConfig = { fancybox: true, animate: true, isHome: false, isPost: true, isArchive: false, isTag: false, isCategory: false, fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js", scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js", search: true } </script> <script> yiliaConfig.jquery_ui = [false]; </script> <script> yiliaConfig.rootUrl = "\/";</script> <script> var _hmt = _hmt || []; (function() { var hm = document.createElement("script"); hm.src = "//hm.baidu.com/hm.js?d71616702a6acb700ae00e15c0b9551b"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); })(); </script> </head></html><!-- rebuild by neat --> <body> <div id="container"> <div class="left-col"> <!-- build time:Mon Nov 18 2019 20:42:34 GMT+0800 (GMT+08:00) --><div class="overlay"></div> <div class="intrude-less"> <header id="header" class="inner"> <a href="/" class="profilepic"> <img src="/img/myportrait1.gif" class="animated zoomIn"> </a> <hgroup> <h1 class="header-author"><a href="/">Porter Pan</a></h1> </hgroup> <p class="header-subtitle">人最先衰老的：不是容貌，而是那不顾一切的闯劲</p> <form id="search-form"> <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" /> <i class="fa fa-times" onclick="resetSearch()"></i> </form> <div id="local-search-result"></div> <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p> <div id="switch-btn" class="switch-btn"> <div class="icon"> <div class="icon-ctn"> <div class="icon-wrap icon-house" data-idx="0"> <div class="birdhouse"></div> <div class="birdhouse_holes"></div> </div> <div class="icon-wrap icon-ribbon hide" data-idx="1"> <div class="ribbon"></div> </div> <div class="icon-wrap icon-link hide" data-idx="2"> <div class="loopback_l"></div> <div class="loopback_r"></div> </div> <div class="icon-wrap icon-me hide" data-idx="3"> <div class="user"></div> <div class="shoulder"></div> </div> </div> </div> <div class="tips-box hide"> <div class="tips-arrow"></div> <ul class="tips-inner"> <li>菜单</li> <li>标签</li> <li>友情链接</li> <li>关于我</li> </ul> </div> </div> <div id="switch-area" class="switch-area"> <div class="switch-wrap"> <section class="switch-part switch-part1"> <nav class="header-menu"> <ul> <li><a href="/">主页</a></li> <li><a href="/archives/">所有文章</a></li> <li><a href="/diary/">随笔</a></li> <li><a href="/tags/">标签云</a></li> <li><a href="/./myResume/">关于我</a></li> </ul> </nav> <nav class="header-nav"> <ul class="social"> <a class="fa Email" href="mailto:porterpan@163.com" title="Email"></a> <a class="fa GitHub" href="https://github.com/porterpan" title="GitHub"></a> <a class="fa GitBook" href="https://porter.gitbook.io" title="GitBook"></a> <a class="fa 博客园" href="https://www.cnblogs.com/pertor/" title="博客园"></a> <a class="fa bilibili" href="http://space.bilibili.com/240704272/#/" title="bilibili"></a> <a class="fa Twitter" href="https://twitter.com/zf_Porter" title="Twitter"></a> <a class="fa 微信" href="/./about/contactme.html" title="微信"></a> <a class="fa WebNavigation" href="/./navs/index.html" title="WebNavigation"></a> </ul> </nav> </section> <section class="switch-part switch-part2"> <div class="widget tagcloud" id="js-tagcloud"> <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayes/">Bayes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Blogs/">Blogs</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C语言/">C语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Error/">Error</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GUI/">GUI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gitbook/">Gitbook</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Github/">Github</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gitment/">Gitment</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KNN/">KNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LRN/">LRN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Latex/">Latex</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Library-Project/">Library Project</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MNIST/">MNIST</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Module/">Module</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Note/">Note</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OpenCV/">OpenCV</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/">PyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pythton/">Pythton</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Qt5/">Qt5</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ROS/">ROS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Socket/">Socket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Socket5/">Socket5</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/System-Conf/">System Conf</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TxtToSpeech/">TxtToSpeech</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/future/">__future__</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/anaconda/">anaconda</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/argparse/">argparse</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/css/">css</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/exam/">exam</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/file/">file</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git/">git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gitignore/">gitignore</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/git命令/">git命令</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/goldendict/">goldendict</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gym/">gym</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gym-gazebo/">gym-gazebo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gym-gazabe/">gym_gazabe</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo-neat/">hexo-neat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jupyter-notebook/">jupyter notebook</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/keras/">keras</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kmean/">kmean</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/logistic-regression/">logistic regression</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/matplotlib/">matplotlib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/">numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/opencv/">opencv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/peek/">peek</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-moudle/">python moudle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/qt5/">qt5</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/recognition/">recognition</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/share/">share</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sublime-test3/">sublime test3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sublime-text/">sublime-text</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/url/">url</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/vsftpd/">vsftpd</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/writen/">writen</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/不能中文输入/">不能中文输入</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/决策树/">决策树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/加载本地图片/">加载本地图片</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/古诗词识别/">古诗词识别</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安利/">安利</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/嵌入式/">嵌入式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/工具/">工具</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/总结/">总结</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/日记/">日记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/最大似然估计/">最大似然估计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/最大熵模型/">最大熵模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/有道词典/">有道词典</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/梯度下降和最小二乘法/">梯度下降和最小二乘法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/笔试/">笔试</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法岗/">算法岗</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/系统引导/">系统引导</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/线性回归/">线性回归</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网站/">网站</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网站压缩/">网站压缩</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网页嵌入/">网页嵌入</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/英文网址/">英文网址</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/评论插件/">评论插件</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/迭代算法/">迭代算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/隐马尔科夫HMM/">隐马尔科夫HMM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/音视频嵌入/">音视频嵌入</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/马尔科夫模型实战/">马尔科夫模型实战</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/验证码/">验证码</a></li></ul> </div> </section> <section class="switch-part switch-part3"> <div id="js-friends"> <a class="main-nav-link switch-friends-link" href="http://scholar.hezibuluo.com/">盒子部落</a> <a class="main-nav-link switch-friends-link" href="http://www.588230.com/">南瓜网</a> <a class="main-nav-link switch-friends-link" href="http://www.wenkuwenku.com/">皮皮虾</a> <a class="main-nav-link switch-friends-link" href="http://www.wuhouge.com/">武侯阁</a> <a class="main-nav-link switch-friends-link" href="https://free-ss.site/">free-ss</a> <a class="main-nav-link switch-friends-link" href="https://www.yiibai.com/git/git_checkout.html">Git命令</a> <a class="main-nav-link switch-friends-link" href="http://www.paperweekly.site/rank">paper Weekly</a> <a class="main-nav-link switch-friends-link" href="https://arxiv.org/">arXiv.org</a> <a class="main-nav-link switch-friends-link" href="http://muchong.com/bbs/">小木虫</a> <a class="main-nav-link switch-friends-link" href="https://redstonewill.com/">红色石头博客</a> <a class="main-nav-link switch-friends-link" href="http://people.csail.mit.edu/leozhu/?from=singlemessage">Leo Zhu</a> <a class="main-nav-link switch-friends-link" href="https://gitbook.cn/">gitchat</a> <a class="main-nav-link switch-friends-link" href="https://www.fast.ai/">fast.Ai</a> <a class="main-nav-link switch-friends-link" href="http://image-net.org/">image-net-ilsvrc</a> <a class="main-nav-link switch-friends-link" href="https://wx.zsxq.com/dweb/#/index/825884414222">知识星球</a> <a class="main-nav-link switch-friends-link" href="https://juejin.im/">掘金</a> <a class="main-nav-link switch-friends-link" href="https://medium.com/">medium</a> <a class="main-nav-link switch-friends-link" href="https://www.savido.net/">savido</a> <a class="main-nav-link switch-friends-link" href="https://www.videosolo.com/zh-CN/online-video-downloader/">videosolo</a> <a class="main-nav-link switch-friends-link" href="https://www.tubeninja.net/zh-hans/">tubeninja</a> </div> </section> <section class="switch-part switch-part4"> <div id="js-aboutme">不要怂，干就是了，力量可能跟不上，气势上一定要跟上；专注于深度学习、机器学习、视觉图像处理、嵌入式软/硬件。</div> </section> </div> </div> </header> </div><!-- rebuild by neat --> </div> <div class="mid-col"> <!-- build time:Mon Nov 18 2019 20:42:34 GMT+0800 (GMT+08:00) --><nav id="mobile-nav"> <div class="overlay"> <div class="slider-trigger"></div> <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Porter Pan</a></h1> </div> <div class="intrude-less"> <header id="header" class="inner"> <a href="/" class="profilepic"> <img src="/img/myportrait1.gif" class="animated zoomIn"> </a> <hgroup> <h1 class="header-author"><a href="/" title="回到主页">Porter Pan</a></h1> </hgroup> <p class="header-subtitle">人最先衰老的：不是容貌，而是那不顾一切的闯劲</p> <nav class="header-menu"> <ul> <li><a href="/">主页</a></li> <li><a href="/archives/">所有文章</a></li> <li><a href="/diary/">随笔</a></li> <li><a href="/tags/">标签云</a></li> <li><a href="/./myResume/">关于我</a></li> <div class="clearfix"></div> </ul> </nav> <nav class="header-nav"> <ul class="social"> <a class="fa Email" target="_blank" href="mailto:porterpan@163.com" title="Email"></a> <a class="fa GitHub" target="_blank" href="https://github.com/porterpan" title="GitHub"></a> <a class="fa GitBook" target="_blank" href="https://porter.gitbook.io" title="GitBook"></a> <a class="fa 博客园" target="_blank" href="https://www.cnblogs.com/pertor/" title="博客园"></a> <a class="fa bilibili" target="_blank" href="http://space.bilibili.com/240704272/#/" title="bilibili"></a> <a class="fa Twitter" target="_blank" href="https://twitter.com/zf_Porter" title="Twitter"></a> <a class="fa 微信" target="_blank" href="/./about/contactme.html" title="微信"></a> <a class="fa WebNavigation" target="_blank" href="/./navs/index.html" title="WebNavigation"></a> </ul> </nav> </header> </div> <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/> </nav><!-- rebuild by neat --> <div class="body-wrap"><!-- build time:Mon Nov 18 2019 20:42:33 GMT+0800 (GMT+08:00) --><!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><article id="post-im5-神经网络笔记-第五章-TensorFlow-MNIST-手写字识别" class="article article-type-post" itemscope itemprop="blogPost"> <div class="article-meta"> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><a href="/tfshouxiezi/" class="article-date"> <time datetime="2019-06-05T14:55:03.000Z" itemprop="datePublished">2019-06-05</time> </a><!-- rebuild by neat --> </div> <div class="article-inner"> <input type="hidden" class="isFancy" /> <header class="article-header"> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><h1 class="article-title" itemprop="name"> 第五章 TensorFlow MNIST 手写字识别笔记 </h1><!-- rebuild by neat --> </header> <div class="article-info article-info-post"> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><div class="article-category tagcloud"> <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a> </div><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><div class="article-tag tagcloud"> <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li></ul> </div><!-- rebuild by neat --> <div class="clearfix"></div> </div> <div class="article-entry" itemprop="articleBody"> <!-- build time:Mon Nov 18 2019 20:42:09 GMT+0800 (GMT+08:00) --><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>本节主要是学习TensorFlow的相关学习笔记，主要是基础的学习路线，包括简单的实例笔记等。</p> <p>内容包括如下：</p> <ul> <li>部分数学推导</li> <li>部分代码实现</li> <li>MNIST手写数字识别的模型训练过程</li> <li>MNIST手写数字识别的模型测试过程</li> <li>MNIST手写数字是别的模型应用</li> </ul> <blockquote> <p>提示本部分是一个PDF手稿，暂时未整理排版，只能在电脑端预览本部分的PDF笔记,手机上的PDF笔记将不会显示出来。</p> </blockquote> <ul> <li style="list-style: none"><input type="checkbox" checked> Edit By Porter, 积水成渊,蛟龙生焉。</li> </ul> <a id="more"></a> <div id="pdf1-view1" class=" pdfobject-container" style="height:400px"><br><embed class="pdfobject" src="/TensorFlow-index/第五章 TensorFlow MNIST 手写字识别.ipynb - Colaboratory.pdf#navpanes=1&amp;view=FitH&amp;pagemode=thumbs&amp;page=3" type="application/pdf" style="overflow: auto; width: 100%; height: 180%;" internalinstanceid="29"><br></div> <div style="height:400px"><br><br></div> <h1 id="五、-TensorFlow-MNIST-手写字识别"><a href="#五、-TensorFlow-MNIST-手写字识别" class="headerlink" title="五、 TensorFlow MNIST 手写字识别"></a>五、 TensorFlow MNIST 手写字识别</h1><h2 id="5-1-具体实现过程"><a href="#5-1-具体实现过程" class="headerlink" title="5.1 具体实现过程"></a>5.1 具体实现过程</h2><p>MNIST 手写字识别的训练图片是28*28寸的图片。</p> <ul> <li>第一层隐藏层</li> </ul> <p>第一步是将图片矩阵打平处理为 $[image]_{1×784}$</p> <p>第二 步是我们将第一层隐藏层将要设置的参数数量，这些数量会影响我们的训练精度，将设我们设置第一层的影藏层权重和偏置参数分别为500个，则可以设置第一个隐藏层的维数为$[\omega_{1}]<em>{784×500}$，同样偏置的维数为$[b</em>{1}]_{1×500}$</p> <ul> <li>第二层隐藏层</li> </ul> <p>第三步是设置第二层隐藏层的权重和偏置维数，因为我们只需要三层神经网络结构实现，所以我们这一层应该做池化实现onehot，输出应该为1×10的独热编码。所以$\omega_{2}$应该是500行和10列。即 $[\omega_{2}]<em>{500×10}$，$[b</em>{2}]_{1×10}$</p> <ul> <li>整个流程</li> </ul> <p><img src="https://s2.ax1x.com/2019/07/31/etxrBn.png" alt="流程"></p> <h2 id="5-2-前向传播"><a href="#5-2-前向传播" class="headerlink" title="5.2 前向传播"></a>5.2 前向传播</h2><p> 训练的过程是，首先输入一批数据，然后对每批数据进行上个流程的计算过程，比如我一批次输入200张图片进行训练。</p> <p><img src="https://s2.ax1x.com/2019/07/31/etxfc4.png" alt="流程"></p> <p> 前向传播算法的代码如下部分代码所示</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">INPUT_NODE = <span class="number">784</span></span><br><span class="line">OUTPUT_NODE = <span class="number">10</span></span><br><span class="line">LAYER1_NODE = <span class="number">500</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span><span class="params">(shape, regularizer)</span>:</span></span><br><span class="line"> w = tf.Variables(tf.truncated_normal(shape,stddev=<span class="number">0.1</span>))</span><br><span class="line"> <span class="keyword">if</span> regularizer != <span class="keyword">None</span>: tf.add_to_collection(<span class="string">'losses'</span>, tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line"> <span class="keyword">return</span> w</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span><span class="params">(shape)</span>:</span> </span><br><span class="line"> b = tf.Variable(tf.zeros(shape)) </span><br><span class="line"> <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(x, regularizer)</span>:</span></span><br><span class="line"> <span class="comment"># []_&#123;784*500&#125;</span></span><br><span class="line"> w1 = get_weight([INPUT_NODE, LAYER1_NODE], regularizer)</span><br><span class="line"> b1 = get_bias([LAYER1_NODE])</span><br><span class="line"><span class="comment"># relu 非线性函数的，修正线性单元</span></span><br><span class="line"> y1 = tf.nn.relu(tf.matmul(x, w1) + b1)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 这里w= get_weight([500, 784] 因为x=[None,784]</span></span><br><span class="line"> w2 = get_weight([LAYER1_NODE, OUTPUT_NODE], regularizer)</span><br><span class="line"> b2 = get_bias([OUTPUT_NODE])</span><br><span class="line"> y = tf.matmul(y1, w2) + b2</span><br><span class="line"> <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure> <h2 id="5-3-反向传播-最小化损失函数"><a href="#5-3-反向传播-最小化损失函数" class="headerlink" title="5.3 反向传播(最小化损失函数)"></a>5.3 反向传播(最小化损失函数)</h2><p>反向传播过程就是利用梯度下降算法进行最佳的各隐藏层的权值和偏置的优化过程。</p> <p>一般选择的梯度优化算法有：</p> <ul> <li>批量梯度优化算法</li> <li>随机梯度优化</li> <li><p>自适应梯度优化</p> </li> <li><p>等等</p> </li> </ul> <p>train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</p> <p>整个流程</p> <p>前向传播输出结果–&gt; 归一化(softmax()) —&gt; 求取每回batch中样本的输出相似度（交叉熵求求相似度sparse_softmax_cross_entropy_with_logits）—&gt; 得到每个batch中每个样本中的交叉熵均值(tf.reduce_mean()) –&gt;<br>正则化输出–&gt; loss(loss = cem + tf.add_n(tf.get_collection(‘losses’)))</p> <p><a href="https://imgchr.com/i/VwajeO" target="_blank" rel="noopener"><img src="https://s2.ax1x.com/2019/06/07/VwajeO.md.png" alt="VwajeO.md.png"></a></p> <hr> <p>相关函数解释：</p> <ul> <li>tf.add_n(p1, p2, p3…)</li> </ul> <p>实现列表中的元素相加</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input1 = tf.constant([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])</span><br><span class="line">input2 = tf.Variable(tf.random_uniform([<span class="number">3</span>]))</span><br><span class="line">output = tf.add_n([input1, input2]) <span class="comment"># = input1 + input2</span></span><br></pre></td></tr></table></figure> <h3 id="5-3-1-Softmax-归一化前向传播输出结果"><a href="#5-3-1-Softmax-归一化前向传播输出结果" class="headerlink" title="5.3.1 Softmax(归一化前向传播输出结果)"></a>5.3.1 Softmax(归一化前向传播输出结果)</h3><p>之前我们选择的代价函数为均方误差函数，表达式为</p> <p>$$<br>loss = \frac{(y-y_)^{2}}{n}<br>$$</p> <p>实现的代码如下：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss_mse = tf.reduce_mean(tf.square(y_ - y))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.001</span>).minimize(loss_mse)</span><br></pre></td></tr></table></figure> <p>Softmax 归一化操作，实现输出各通道的数值编程, 概率和为1的概率表达形式</p> <p>$$<br>\mathit{<br>y_{j} = \frac{e^{z^{j}}}{\sum\limits <em>{i} e^{z</em>{i}}}<br>}<br>$$</p> <p><img src="https://s2.ax1x.com/2019/06/07/Vw10Zn.png" alt="Vw10Zn.png"></p> <p>如上图所示，softmax函数的作用是归一化，将所有的输出以概率和为1的方式，将输出结果用概率表示。</p> <h3 id="5-3-2-交叉熵-比较输出和样本标签的相似度"><a href="#5-3-2-交叉熵-比较输出和样本标签的相似度" class="headerlink" title="5.3.2 交叉熵(比较输出和样本标签的相似度)"></a>5.3.2 交叉熵(比较输出和样本标签的相似度)</h3><p>本部分我们不简单的使用均方误差函数，而是使用交叉熵的方式实现</p> <p>$$<br>H_{y_ (y)} = - \sum_{i}^{} y_{i} _log(y_{i})<br>$$</p> <p>$y_$为样本的标签，而$y$为前向传播的输出计算结果。</p> <p>例子：</p> <p>$$<br>y=[0.005899750.87560060.11849965] $$</p> <p>,也就是如果batch为1(输入的训练数据，只输入1组含有一个样本的数据，一般训练一个batch会包含多个batch所以，会对本次的batch中的多个交叉熵求取均值“ tf.reduce_mean(ce)”)</p> <p>$$<br>H_{y_ (y)} =−0×log(0.00589975)−1×log(0.8756006)−0×log(0.11849965) \<br>=0.6355716 -0\times log(0.00589975)-1\times log(0.8756006)-0\times log(0.11849965) \<br>= 0.6355716−0×log(0.00589975)−1×log(0.8756006)−0×log(0.11849965) \<br>=0.6355716<br>$$</p> <p>实现的代码如下</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">cem = tf.reduce_mean(ce)</span><br><span class="line">loss = cem + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br></pre></td></tr></table></figure> <p>这里的logits=y, 是前向传播中的3层神经网络的输出层结果$y_{[200×10]}$</p> <hr> <ul> <li><p>tf.nn.sparse_softmax_cross_entropy_with_logits()与tf.nn.softmax_cross_entropy_with_logits的差别</p> <p>sparse_softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, name=None)</p> </li> </ul> <font color="blue">唯一的区别是sparse的labels是int类型，而非sparse的labels是one-hot类型。</font> <ul> <li>tf.argmax(input,axis)根据axis取值的不同返回每行或者每列最大值的索引</li> </ul> <p>axis = 0: </p> <p> axis=0时比较每一列的元素，将每一列最大元素所在的索引记录下来，最后输出每一列最大元素所在的索引数组。</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">test[<span class="number">0</span>] = array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">test[<span class="number">1</span>] = array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">test[<span class="number">2</span>] = array([<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">test[<span class="number">3</span>] = array([<span class="number">8</span>, <span class="number">7</span>, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># output : [3, 3, 1]</span></span><br></pre></td></tr></table></figure> <p>axis = 1: </p> <p> axis=1的时候，将每一行最大元素所在的索引记录下来，最后返回每一行最大元素所在的索引数组。</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test[<span class="number">0</span>] = array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]) <span class="comment">#2</span></span><br><span class="line">test[<span class="number">1</span>] = array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]) <span class="comment">#2</span></span><br><span class="line">test[<span class="number">2</span>] = array([<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>]) <span class="comment">#0</span></span><br><span class="line">test[<span class="number">3</span>] = array([<span class="number">8</span>, <span class="number">7</span>, <span class="number">2</span>]) <span class="comment">#0</span></span><br></pre></td></tr></table></figure> <h3 id="5-3-3-batch个样本的交叉熵后整体均值计算"><a href="#5-3-3-batch个样本的交叉熵后整体均值计算" class="headerlink" title="5.3.3 batch个样本的交叉熵后整体均值计算"></a>5.3.3 batch个样本的交叉熵后整体均值计算</h3><p>cem = tf.reduce_mean(ce)</p> <hr> <p>reduce_mean()函数的用法举例</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"> </span><br><span class="line">x = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line"> [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br><span class="line"> </span><br><span class="line">xx = tf.cast(x,tf.float32)</span><br><span class="line"> </span><br><span class="line">mean_all = tf.reduce_mean(xx, keep_dims=<span class="keyword">False</span>)</span><br><span class="line">mean_0 = tf.reduce_mean(xx, axis=<span class="number">0</span>, keep_dims=<span class="keyword">False</span>)</span><br><span class="line">mean_1 = tf.reduce_mean(xx, axis=<span class="number">1</span>, keep_dims=<span class="keyword">False</span>)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> m_a,m_0,m_1 = sess.run([mean_all, mean_0, mean_1])</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> m_a <span class="comment"># output: 2.0</span></span><br><span class="line"><span class="keyword">print</span> m_0 <span class="comment"># output: [ 1. 2. 3.]</span></span><br><span class="line"><span class="keyword">print</span> m_1 <span class="comment">#output: [ 2. 2.]</span></span><br></pre></td></tr></table></figure> <h3 id="5-3-4-正则化"><a href="#5-3-4-正则化" class="headerlink" title="5.3.4 正则化"></a>5.3.4 正则化</h3><p>在前向传播中将正则化对象设置成$\omega$</p> <p> $L^{2}$参数正则化</p> <p> $$\Omega(\theta)=\frac{1}{2} ||\omega||^{2}_{2}$$</p> <p>将上面的公式整理可得到</p> <p>$$<br>\widetilde{J}(\omega;X,y) = J(\omega;X,y)+\alpha \Omega(\theta) \<br>= J(\omega;X,y)+ \frac{\alpha}{2} \omega^{\top}\omega<br>$$</p> <p>与之对应的梯度为：</p> <p>$$<br>\triangledown_{\omega} \widetilde{J}(\omega;X,y)=\alpha \omega + \triangledown_{\omega}J(\omega;X,y)<br>$$</p> <p>得到$L^{2}$参数正则化的参数$\omega$参数更新的表达式为</p> <p>$$<br>\omega \leftarrow \omega - \epsilon \triangledown_{\omega} \widetilde{J}(\omega;X,y)<br>$$</p> <p>正则化后的代价函数$J(\omega;X,y)$实现代码为</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = cem + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br></pre></td></tr></table></figure> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="comment"># import mnist_forward</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">200</span></span><br><span class="line">LEARNING_RATE_BASE = <span class="number">0.1</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span></span><br><span class="line">REGULARIZER = <span class="number">0.0001</span></span><br><span class="line">STEPS = <span class="number">50000</span></span><br><span class="line">MOVING_AVERAGE_DECAY = <span class="number">0.99</span></span><br><span class="line">MODEL_SAVE_PATH=<span class="string">"./model/"</span></span><br><span class="line">MODEL_NAME=<span class="string">"mnist_model"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(mnist)</span>:</span></span><br><span class="line"></span><br><span class="line"> x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line"> y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.OUTPUT_NODE])</span><br><span class="line"> y = mnist_forward.forward(x, REGULARIZER)</span><br><span class="line"> global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)	</span><br><span class="line"> </span><br><span class="line"> ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line"> cem = tf.reduce_mean(ce)</span><br><span class="line"> loss = cem + tf.add_n(tf.get_collection(<span class="string">'losses'</span>))</span><br><span class="line"></span><br><span class="line"> learning_rate = tf.train.exponential_decay(</span><br><span class="line"> LEARNING_RATE_BASE,</span><br><span class="line"> global_step,</span><br><span class="line"> mnist.train.num_examples / BATCH_SIZE, </span><br><span class="line"> LEARNING_RATE_DECAY,</span><br><span class="line"> staircase=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"> train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line"> ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)</span><br><span class="line"> ema_op = ema.apply(tf.trainable_variables())</span><br><span class="line"> <span class="keyword">with</span> tf.control_dependencies([train_step, ema_op]):</span><br><span class="line"> train_op = tf.no_op(name=<span class="string">'train'</span>)</span><br><span class="line"></span><br><span class="line"> saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"> <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> init_op = tf.global_variables_initializer()</span><br><span class="line"> sess.run(init_op)</span><br><span class="line"></span><br><span class="line"> ckpt = tf.train.get_checkpoint_state(MODEL_SAVE_PATH)</span><br><span class="line"> <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line"> saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line"></span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line"> xs, ys = mnist.train.next_batch(BATCH_SIZE)</span><br><span class="line"> _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict=&#123;x: xs, y_: ys&#125;)</span><br><span class="line"> <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line"> print(<span class="string">"After %d training step(s), loss on training batch is %g."</span> % (step, loss_value))</span><br><span class="line"> saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line"> mnist = input_data.read_data_sets(<span class="string">"./data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"> backward(mnist)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"> main()</span><br></pre></td></tr></table></figure> <h2 id="5-4-训练过程"><a href="#5-4-训练过程" class="headerlink" title="5.4 训练过程"></a>5.4 训练过程</h2><h3 id="5-4-1-指数衰减学习率"><a href="#5-4-1-指数衰减学习率" class="headerlink" title="5.4.1 指数衰减学习率"></a>5.4.1 指数衰减学习率</h3><p>训练过程我们使用指数衰减学习率实现，梯度下降算法中的学习率以指数形式衰减，可以提高训练的效率。</p> <p>指数衰减学习率的公式为：</p> <p>$$<br>dlr = lr * dr ^{\frac{globals}{decays}}<br>$$</p> <p>各个简写分别为</p> <table> <thead> <tr> <th style="text-align:left">简写</th> <th style="text-align:left">对应的全程</th> <th style="text-align:left">代表的含义</th> </tr> </thead> <tbody> <tr> <td style="text-align:left">dlr</td> <td style="text-align:left">decayed_learning_rate</td> <td style="text-align:left">指数衰减学习率</td> </tr> <tr> <td style="text-align:left">lr</td> <td style="text-align:left">learining_rate</td> <td style="text-align:left">为学习率初始设定值</td> </tr> <tr> <td style="text-align:left">dr</td> <td style="text-align:left">decay_rate</td> <td style="text-align:left">为学习率的衰减率</td> </tr> <tr> <td style="text-align:left">globals</td> <td style="text-align:left">global_step</td> <td style="text-align:left">记录了当前训练轮数</td> </tr> <tr> <td style="text-align:left">decays</td> <td style="text-align:left">decay_steps</td> <td style="text-align:left">多少轮更新一次学习率</td> </tr> </tbody> </table> <p>也可以用如下的表达式表示指数衰减学习率的表示</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">decayed_learning_rate=learining_rate*decay_rate^(global_step/decay_steps)</span><br></pre></td></tr></table></figure> <p>具体的实现代码如下：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exponential_decay</span><span class="params">(learning_rate,</span></span></span><br><span class="line"><span class="function"><span class="params"> global_step,</span></span></span><br><span class="line"><span class="function"><span class="params"> decay_steps,</span></span></span><br><span class="line"><span class="function"><span class="params"> decay_rate,</span></span></span><br><span class="line"><span class="function"><span class="params"> staircase=False,</span></span></span><br><span class="line"><span class="function"><span class="params"> name=None)</span>:</span></span><br></pre></td></tr></table></figure> <p>函数的的使用</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">LEARNING_RATE_BASE = <span class="number">0.8</span></span><br><span class="line">BATCH_SIZE = <span class="number">200</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span></span><br><span class="line">global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="keyword">False</span>)</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line">learning_rate = tf.train.exponential_decay(learning_rate = LEARNING_RATE_BASE,</span><br><span class="line"> global_step = global_step,</span><br><span class="line"> decay_steps = mnist.train.num_examples / BATCH_SIZE,</span><br><span class="line"> decay_rate = LEARNING_RATE_DECAY,</span><br><span class="line"> staircase=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure> <h3 id="5-4-2-梯度下降并开始迭代训练"><a href="#5-4-2-梯度下降并开始迭代训练" class="headerlink" title="5.4.2 梯度下降并开始迭代训练"></a>5.4.2 梯度下降并开始迭代训练</h3><p>上面步骤确定了学习率，并且5.2 节也确定了前向传播，5.3节确定了代价函数，此时可以进行梯度下降算法的迭代训练模型参数</p> <p>模型的训练，此处选择梯度下降算法，开始训练模型参数，代码如下</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</span><br></pre></td></tr></table></figure> <h3 id="5-4-3-滑动平均优化模型参数"><a href="#5-4-3-滑动平均优化模型参数" class="headerlink" title="5.4.3 滑动平均优化模型参数"></a>5.4.3 滑动平均优化模型参数</h3><p>滑动平均可以使训练的模型能在测试数据上更加健壮(好的泛化能力、鲁棒性好),其实滑动平均模型，主要是通过控制衰减率来控制参数更新前后之间的差距，从而达到减缓参数的变化值（如，参数更新前是5，更新后的值是4，通过滑动平均模型之后，参数的值会在4到5之间），如果参数更新前后的值保持不变，通过滑动平均模型之后，参数的值仍然保持不变。</p> <p>函数的原型如下</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.ExponentialMovingAverage(decay, num_updates=<span class="keyword">None</span>, zero_debias=<span class="keyword">False</span>,name=<span class="string">"ExponentialMovingAverage"</span>)</span><br></pre></td></tr></table></figure> <font color="red"><br>参数：<br><br><br>decay：实数类型，衰减率。<br><br>num_updates：可选，为轮数，设置这个参数之后，将会通过min(decay, (1 + num_updates) / (10 + num_updates))函数，从中选择最小值做为衰减率。<br><br><font color="red"><br>返回值：<br></font> <pre><code>ExponentialMovingAverage对象，通过对象调用apply方法可以通过滑动平均模型来更新参数。 </code></pre><font color="red"><br>计算公式：<br> </font> <p>shadow_variable = decay <em> shadow_variable + (1-decay) </em> variable</p> <p>计算公式中的shadow_variable为影子变量，也就是变量在更新之前的值，variable是变量现在的值，可能这样说不是很明白，下面用TensorFlow的程序来实现滑动平均模型。</p> <p>本次模型训练使用的滑动平均算法调用如下：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ma_decay = <span class="number">0.99</span></span><br><span class="line">ema = tf.train.ExponentialMovingAverage(decay = ma_decay, </span><br><span class="line"> num_updates = global_step)	</span><br><span class="line">ema_op = ema.apply(tf.trainable_variables())</span><br></pre></td></tr></table></figure> <p>总结下；</p> <p>滑动平均值的参数更新，比如对权重$\omega_{1}$更新，开始轮数为num_updates= 0 次时，$\omega_{1}$初值设置0, 第1轮更新为variable=1($\omega_{1}=1$); decay=0.99 ;此时有：</p> <p>$\omega_{1}$ = $min(ma_decay, \frac{1+0}{10+0})<em>0+(1-min(1-min(decay,\frac{1+0}{10+0})</em>1))= 0.1<em>0+(1-0.9)</em>1=0.9$</p> <p>训练过程的代码如下：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> mnist_forward</span><br><span class="line"><span class="keyword">import</span> mnist_backward</span><br><span class="line">TEST_INTERVAL_SECS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(mnist)</span>:</span></span><br><span class="line"> <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> g:</span><br><span class="line"> x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line"> y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.OUTPUT_NODE])</span><br><span class="line"> y = mnist_forward.forward(x, <span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"> ema = tf.train.ExponentialMovingAverage(mnist_backward.MOVING_AVERAGE_DECAY)</span><br><span class="line"> ema_restore = ema.variables_to_restore()</span><br><span class="line"> saver = tf.train.Saver(ema_restore)</span><br><span class="line"> </span><br><span class="line"> correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line"> accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) </span><br><span class="line"></span><br><span class="line"> <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line"> <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> ckpt = tf.train.get_checkpoint_state(mnist_backward.MODEL_SAVE_PATH)</span><br><span class="line"> <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line"> saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line"> global_step = ckpt.model_checkpoint_path.split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'-'</span>)[<span class="number">-1</span>]</span><br><span class="line"> accuracy_score = sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)</span><br><span class="line"> print(<span class="string">"After %s training step(s), test accuracy = %g"</span> % (global_step, accuracy_score))</span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line"> print(<span class="string">'No checkpoint file found'</span>)</span><br><span class="line"> <span class="keyword">return</span></span><br><span class="line"> time.sleep(TEST_INTERVAL_SECS)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line"> mnist = input_data.read_data_sets(<span class="string">"../MNIST_data/"</span>, one_hot=<span class="keyword">True</span>)</span><br><span class="line"> test(mnist)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"> main()</span><br></pre></td></tr></table></figure> <h2 id="5-5-模型训练后的断点保存和恢复"><a href="#5-5-模型训练后的断点保存和恢复" class="headerlink" title="5.5 模型训练后的断点保存和恢复"></a>5.5 模型训练后的断点保存和恢复</h2><h3 id="5-5-1-保存模型"><a href="#5-5-1-保存模型" class="headerlink" title="5.5.1 保存模型"></a>5.5.1 保存模型</h3><p>在反向传播中，为防止模型训练过程中由于硬件或者断电的情况下，使模型前期训练全部失效，我们一般会在训练了一定间隔轮数后保存当前训练后的神经网络模型。</p> <p>保存模型后会产生3个文件。 </p> <ul> <li>保存当前图解钩的.meta文件</li> <li>保存当前参数名的.index文件</li> <li>保存当前参数的.data文件</li> </ul> <p>具体的保存过程代码，如下</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">MODEL_SAVE_PATH = <span class="string">"./model/"</span></span><br><span class="line">MODEL_NAME = <span class="string">"mnist_model"</span></span><br><span class="line">saver = tf.train.Server()<span class="comment"># 实例化Sever对象</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(STEPS):</span><br><span class="line"> <span class="keyword">if</span> i%轮数 == <span class="number">0</span>:</span><br><span class="line"> saver.save(sess, os.path.join(MODEL_SAVE_PATH,</span><br><span class="line"> MODEL_NAME), global_step = global_step)</span><br></pre></td></tr></table></figure> <p>os.path.join() 是将括号中的参数都变成路径的字符形式。</p> <p>比如，当前的global_step=100，则save后的文件名是“./model/mnist_model-100.meta、./model/mnist_model-100.index ”等</p> <h3 id="5-5-2-恢复模型"><a href="#5-5-2-恢复模型" class="headerlink" title="5.5.2 恢复模型"></a>5.5.2 恢复模型</h3><p>恢复训练中的神经网络模型</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ckpt = tf.train.get_checkpoint_state(mnist_backward.MODEL_SAVE_PATH)</span><br><span class="line"> <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line"> saver.restore(sess, ckpt.model_checkpoint_path)</span><br></pre></td></tr></table></figure> <p>恢复模型中调用的滑动平均模型参数</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ema = tf.train.ExponentialMovingAverage(滑动平均基数)</span><br><span class="line">ema_restore = ema.variables_to_restore()</span><br><span class="line">saver = tf.train.Saver(ema_restore)</span><br></pre></td></tr></table></figure> <h2 id="5-6-验证阶段神经网络模型准确性的评估方法"><a href="#5-6-验证阶段神经网络模型准确性的评估方法" class="headerlink" title="5.6 验证阶段神经网络模型准确性的评估方法"></a>5.6 验证阶段神经网络模型准确性的评估方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>),tf.argmax(y_, <span class="number">1</span>))<span class="comment"># 返回的都是bool型变量</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))<span class="comment"># 将bool型转化为float型，然后求均值</span></span><br></pre></td></tr></table></figure> <p>对训练后的模型进行准确度评判</p> <p>神经网络的测试验证阶段，只需要前向传播的模型，不需要对模型参数进行梯度下降的迭代优化，具体的过程入下</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> g:</span><br><span class="line"> x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line"> y_ = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.OUTPUT_NODE])</span><br><span class="line"> y = mnist_forward.forward(x, <span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line"> ema = tf.train.ExponentialMovingAverage(mnist_backward.MOVING_AVERAGE_DECAY)</span><br><span class="line"> ema_restore = ema.variables_to_restore()</span><br><span class="line"> saver = tf.train.Saver(ema_restore)</span><br><span class="line"></span><br><span class="line"> correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line"> accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"> </span><br><span class="line"> <span class="comment"># 开始读取保存后的神经网络模型参数，恢复到我们复制Graph()中 ，然后开始准确性判断</span></span><br><span class="line"> <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> ckpt = tf.train.get_checkpoint_state(mnist_backward.MODEL_SAVE_PATH)</span><br><span class="line"> <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line"> saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line"> global_step = ckpt.model_checkpoint_path.split(<span class="string">'/'</span>)[<span class="number">-1</span>].split(<span class="string">'-'</span>)[<span class="number">-1</span>]</span><br><span class="line"> accuracy_score = sess.run(accuracy, feed_dict=&#123;x:mnist.test.images, y_:mnist.test.labels&#125;)</span><br><span class="line"> print(<span class="string">"After %s training step(s), test accuracy = %g"</span> % (global_step, accuracy_score))</span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line"> print(<span class="string">'No checkpoint file found'</span>)</span><br><span class="line"> <span class="keyword">return</span></span><br></pre></td></tr></table></figure> <h2 id="5-7-训练后的模型使用"><a href="#5-7-训练后的模型使用" class="headerlink" title="5.7 训练后的模型使用"></a>5.7 训练后的模型使用</h2><p>本部分的过程和测试部分的过程稍微不同的是，需要引入输入待识别的图片的图像预处理工作。</p> <p>预处理工作，应该是如下步骤</p> <ul> <li>图片的灰度化（0-255取值范围）</li> <li>将灰度化处理后的图片像素取值进行缩放（0-1的取值范围np.multiply(nm_arr, 1.0/255.0)）</li> <li>图像的reshape</li> </ul> <p>复制神经网络计算图</p> <p>tf.Graph().as_default()</p> <p>然后重保存的神经网络训练参数文件中恢复模型参数</p> <p>（和测试程序一样，这部分也不需要反向传播优化模型参数）</p> <p>然后就是用前向传播计算的流程一样</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line">y = mnist_forward.forward(x, <span class="keyword">None</span>)</span><br><span class="line">preValue = tf.argmax(y, <span class="number">1</span>)</span><br></pre></td></tr></table></figure> <p>具体的整体代码如下部分所示</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> mnist_backward</span><br><span class="line"><span class="keyword">import</span> mnist_forward</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restore_model</span><span class="params">(testPicArr)</span>:</span></span><br><span class="line"> <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> tg:</span><br><span class="line"> x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line"> y = mnist_forward.forward(x, <span class="keyword">None</span>)</span><br><span class="line"> preValue = tf.argmax(y, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"> variable_averages = tf.train.ExponentialMovingAverage(mnist_backward.MOVING_AVERAGE_DECAY)</span><br><span class="line"> variables_to_restore = variable_averages.variables_to_restore()</span><br><span class="line"> saver = tf.train.Saver(variables_to_restore)</span><br><span class="line"></span><br><span class="line"> <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"> ckpt = tf.train.get_checkpoint_state(mnist_backward.MODEL_SAVE_PATH)</span><br><span class="line"> <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line"> saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line"> </span><br><span class="line"> preValue = sess.run(preValue, feed_dict=&#123;x:testPicArr&#125;)</span><br><span class="line"> <span class="keyword">return</span> preValue</span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line"> print(<span class="string">"No checkpoint file found"</span>)</span><br><span class="line"> <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pre_pic</span><span class="params">(picName)</span>:</span></span><br><span class="line">	img = Image.open(picName)</span><br><span class="line">	reIm = img.resize((<span class="number">28</span>,<span class="number">28</span>), Image.ANTIALIAS)</span><br><span class="line">	im_arr = np.array(reIm.convert(<span class="string">'L'</span>))</span><br><span class="line">	threshold = <span class="number">50</span></span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">28</span>):</span><br><span class="line"> <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">28</span>):</span><br><span class="line"> im_arr[i][j] = <span class="number">255</span> - im_arr[i][j]</span><br><span class="line"> <span class="keyword">if</span> (im_arr[i][j] &lt; threshold):</span><br><span class="line"> im_arr[i][j] = <span class="number">0</span></span><br><span class="line"> <span class="keyword">else</span>: im_arr[i][j] = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">	nm_arr = im_arr.reshape([<span class="number">1</span>, <span class="number">784</span>])</span><br><span class="line">	nm_arr = nm_arr.astype(np.float32)</span><br><span class="line">	img_ready = np.multiply(nm_arr, <span class="number">1.0</span>/<span class="number">255.0</span>)</span><br><span class="line"></span><br><span class="line"> <span class="keyword">return</span> img_ready</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">application</span><span class="params">()</span>:</span></span><br><span class="line">	testNum = input(<span class="string">"input the number of test pictures:"</span>)</span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> range(testNum):</span><br><span class="line"> testPic = raw_input(<span class="string">"the path of test picture:"</span>)</span><br><span class="line"> testPicArr = pre_pic(testPic)</span><br><span class="line"> preValue = restore_model(testPicArr)</span><br><span class="line"> print(<span class="string">"The prediction number is:"</span>, preValue)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">	application()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">	main()</span><br></pre></td></tr></table></figure><!-- rebuild by neat --></font> </div> </div> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><div class="copyright"> <p><span>本文标题:</span><a href="/tfshouxiezi/">第五章 TensorFlow MNIST 手写字识别笔记</a></p> <p><span>文章作者:</span><a href="/" title="回到主页">Porter Pan</a></p> <p><span>发布时间:</span>2019-06-05, 22:55:03</p> <p><span>最后更新:</span>2019-09-16, 21:26:47</p> <p> <span>原始链接:</span><a class="post-url" href="/tfshouxiezi/" title="第五章 TensorFlow MNIST 手写字识别笔记">https://blogs.porterpan.top/tfshouxiezi/</a> <span class="copy-path" data-clipboard-text="原文: https://blogs.porterpan.top/tfshouxiezi/　　作者: Porter Pan" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span> <script> var clipboard = new Clipboard('.copy-path'); </script> </p> <p> <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。 </p> </div> <nav id="article-nav"> <div id="article-nav-newer" class="article-nav-title"> <a href="/tfCNN7/"> 第七章 TensorFlow 卷积神经网络 </a> </div> <div id="article-nav-older" class="article-nav-title"> <a href="/tfyouhua4/"> 第四章个人笔记-神经网络优化笔记 </a> </div> </nav><!-- rebuild by neat --> </article> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><div id="toc" class="toc-article"> <strong class="toc-title">文章目录</strong> <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#摘要"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#五、-TensorFlow-MNIST-手写字识别"><span class="toc-number">2.</span> <span class="toc-text">五、 TensorFlow MNIST 手写字识别</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-具体实现过程"><span class="toc-number">2.1.</span> <span class="toc-text">5.1 具体实现过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-前向传播"><span class="toc-number">2.2.</span> <span class="toc-text">5.2 前向传播</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-反向传播-最小化损失函数"><span class="toc-number">2.3.</span> <span class="toc-text">5.3 反向传播(最小化损失函数)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1-Softmax-归一化前向传播输出结果"><span class="toc-number">2.3.1.</span> <span class="toc-text">5.3.1 Softmax(归一化前向传播输出结果)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-交叉熵-比较输出和样本标签的相似度"><span class="toc-number">2.3.2.</span> <span class="toc-text">5.3.2 交叉熵(比较输出和样本标签的相似度)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-3-batch个样本的交叉熵后整体均值计算"><span class="toc-number">2.3.3.</span> <span class="toc-text">5.3.3 batch个样本的交叉熵后整体均值计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-4-正则化"><span class="toc-number">2.3.4.</span> <span class="toc-text">5.3.4 正则化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-训练过程"><span class="toc-number">2.4.</span> <span class="toc-text">5.4 训练过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-1-指数衰减学习率"><span class="toc-number">2.4.1.</span> <span class="toc-text">5.4.1 指数衰减学习率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-2-梯度下降并开始迭代训练"><span class="toc-number">2.4.2.</span> <span class="toc-text">5.4.2 梯度下降并开始迭代训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-3-滑动平均优化模型参数"><span class="toc-number">2.4.3.</span> <span class="toc-text">5.4.3 滑动平均优化模型参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-5-模型训练后的断点保存和恢复"><span class="toc-number">2.5.</span> <span class="toc-text">5.5 模型训练后的断点保存和恢复</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-1-保存模型"><span class="toc-number">2.5.1.</span> <span class="toc-text">5.5.1 保存模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-2-恢复模型"><span class="toc-number">2.5.2.</span> <span class="toc-text">5.5.2 恢复模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-6-验证阶段神经网络模型准确性的评估方法"><span class="toc-number">2.6.</span> <span class="toc-text">5.6 验证阶段神经网络模型准确性的评估方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-7-训练后的模型使用"><span class="toc-number">2.7.</span> <span class="toc-text">5.7 训练后的模型使用</span></a></li></ol></li></ol> </div> <style> .left-col .switch-btn, .left-col .switch-area { display: none; } .toc-level-4 i, .toc-level-4 ol { display: none !important; } </style> <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录"> <script> yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"]; </script><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><div class="share"> <div class="bdsharebuttonbox"> <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a> <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a> <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a> <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a> <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a> <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a> <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a> </div> <script> window._bd_share_config={ "common":{"bdSnsKey":{},"bdText":"第五章 TensorFlow MNIST 手写字识别笔记　| Porter-聚水渊　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)]; </script> </div><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><div id="gitment-ctn"></div> <!--汉化--> <link rel="stylesheet" href="https://porterpan.github.io/gitment/link_src/gitment.css"> <script src="https://porterpan.github.io/gitment/link_src/gitment.js"></script> <!--
<link rel="stylesheet" href="gitment/gitment.css"> <script src="gitment/gitment.js"></script> --> <!--原型--> <!--
<link rel="stylesheet" href="//imsun.github.io/gitment/style/default.css"> <script src="//imsun.github.io/gitment/dist/gitment.browser.js"></script> --> <script> var gitment = new Gitment({ id: "https://blogs.porterpan.top/tfshouxiezi/", owner: 'porterpan', repo: 'porterpan.github.io', oauth: { client_id: '9461105c752e5503b4de', client_secret: 'f2c5ffeac82d7dcdad2e06aceed9320bff0694dc', }, }) gitment.render('gitment-ctn') </script><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:16 GMT+0800 (GMT+08:00) --><div class="scroll" id="post-nav-button"> <a href="/tfCNN7/" title="上一篇: 第七章 TensorFlow 卷积神经网络"> <i class="fa fa-angle-left"></i> </a> <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a> <a href="/tfyouhua4/" title="下一篇: 第四章个人笔记-神经网络优化笔记"> <i class="fa fa-angle-right"></i> </a> </div> <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/keras_checkpoint_rstore/">3.15必应网站爬取清的人脸图片</a></li><li class="post-list-item"><a class="post-list-link" href="/keras_checkpoint_rstore/">3.14keras训练的断点保存和恢复</a></li><li class="post-list-item"><a class="post-list-link" href="/face_recognition_dataset/">3.13自己制作人脸识别数据集</a></li><li class="post-list-item"><a class="post-list-link" href="/opencv_haar/">3.11opencv中haar检测器的使用</a></li><li class="post-list-item"><a class="post-list-link" href="/keras_face_recognition/">3.12keras人脸识别</a></li><li class="post-list-item"><a class="post-list-link" href="/RMBRecognition/">3.10keras人民币识别</a></li><li class="post-list-item"><a class="post-list-link" href="/cuda_encour_problem/">3.9CUDA使用过程中的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/keras_cat_dogs_model_load/">3.8 keras 入门模型保存和加载之猫狗识别</a></li><li class="post-list-item"><a class="post-list-link" href="/keras_cat_dogs/">3.7 keras入门之猫狗分类</a></li><li class="post-list-item"><a class="post-list-link" href="/keras_basic/">3.5 keras 入门</a></li><li class="post-list-item"><a class="post-list-link" href="/keras_MNIST/">3.6 keras 之手写字识别</a></li><li class="post-list-item"><a class="post-list-link" href="/TxtToSpeech/">语音合成小工具</a></li><li class="post-list-item"><a class="post-list-link" href="/heapAndStack/">堆和栈的相关笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/staticstringnum/">输入一串字符串统计字符个数</a></li><li class="post-list-item"><a class="post-list-link" href="/huawei-qishuiping/">华为软件笔试---汽水瓶编程</a></li><li class="post-list-item"><a class="post-list-link" href="/writenexam/">python在线笔试学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/filetosendanyway/">方便的在线高速文件共享</a></li><li class="post-list-item"><a class="post-list-link" href="/anacondaError/">anaconda运行出错现象及解决办法</a></li><li class="post-list-item"><a class="post-list-link" href="/argparsenotes/">argparse模块使用学习笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/htmlyasuo/">hexo-neat网页代码压缩去空格</a></li><li class="post-list-item"><a class="post-list-link" href="/bolgwriteformat/">基于本修改过主题的blog写作格式</a></li><li class="post-list-item"><a class="post-list-link" href="/zjtdbs/">字节跳动笔试-算法岗（2019/07/31）</a></li><li class="post-list-item"><a class="post-list-link" href="/hexoYeleeUrl/">hexo Yelee网址修改为简短的英文</a></li><li class="post-list-item"><a class="post-list-link" href="/hexoFitment/">hexo添加Gitment评论功能</a></li><li class="post-list-item"><a class="post-list-link" href="/jupyterGrammer/">jupyter notebook 使用</a></li><li class="post-list-item"><a class="post-list-link" href="/pdfqianruyulan/">PDF在线预览嵌入到文章中的模板</a></li><li class="post-list-item"><a class="post-list-link" href="/cifar10notes/">CIFAR-10 图像分类Notes</a></li><li class="post-list-item"><a class="post-list-link" href="/gushiciyanzheng/">古诗词验证码使用百度api自动识别</a></li><li class="post-list-item"><a class="post-list-link" href="/hexoloadlocalimage/">hexo加载本地图片的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/kmeans/">2.14 kmeans算法</a></li><li class="post-list-item"><a class="post-list-link" href="/GBDT/">2.15 机器学习算法GBDT</a></li><li class="post-list-item"><a class="post-list-link" href="/dockerCommand/">1.20 docker 基础</a></li><li class="post-list-item"><a class="post-list-link" href="/dockerConf/">docker 配置权限问题</a></li><li class="post-list-item"><a class="post-list-link" href="/tfCNN7/">第七章 TensorFlow 卷积神经网络</a></li><li class="post-list-item"><a class="post-list-link" href="/tfshouxiezi/">第五章 TensorFlow MNIST 手写字识别笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/tfyouhua4/">第四章个人笔记-神经网络优化笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/linuxPDF/">跨平台好用且小巧的pdf阅读器</a></li><li class="post-list-item"><a class="post-list-link" href="/musicplug/">web中插入视频和音乐播放</a></li><li class="post-list-item"><a class="post-list-link" href="/tfnotesp1/">TensorFlow的相关学习笔记 part1</a></li><li class="post-list-item"><a class="post-list-link" href="/ml&dlcomference/">机器学习-深度学习顶级会议罗列</a></li><li class="post-list-item"><a class="post-list-link" href="/installopencv/">1.18 ubuntu下安装OpenCV 3.4.3</a></li><li class="post-list-item"><a class="post-list-link" href="/installopencvs/">1.18 ubuntu下安装OpenCV 3.4.3</a></li><li class="post-list-item"><a class="post-list-link" href="/gymGazabeInstall/">1.19 gym_gazabe安装配置</a></li><li class="post-list-item"><a class="post-list-link" href="/ubuntuinstallGym/">ubuntu16 安装gym-gazebo</a></li><li class="post-list-item"><a class="post-list-link" href="/gym-gazeboInstall/">gym-gazebo安装后的测试</a></li><li class="post-list-item"><a class="post-list-link" href="/DQNgym/">基于DQN的gym_gazebo运行代码演示</a></li><li class="post-list-item"><a class="post-list-link" href="/ros&gazeboInstall/">ros and gazebo and gym_gazebo安装</a></li><li class="post-list-item"><a class="post-list-link" href="/gymError/">gym 运行常见错误及解决办法</a></li><li class="post-list-item"><a class="post-list-link" href="/liberarytool/">图书馆占座小工具使用手册</a></li><li class="post-list-item"><a class="post-list-link" href="/linuxyoudaodict/">1.17 ubuntu下安装有道词典</a></li><li class="post-list-item"><a class="post-list-link" href="/inputU18/">1.16 ubuntu18升级后部分应用不能中文输入的问题</a></li><li class="post-list-item"><a class="post-list-link" href="/goldendictsetting/">1.15 ubuntu下goldendict有道爬虫小程序</a></li><li class="post-list-item"><a class="post-list-link" href="/vsftpdconf/">1.12 vsftpd 文件配置</a></li><li class="post-list-item"><a class="post-list-link" href="/peektool/">1.14 ubuntu16_18安装peek工具录制gif</a></li><li class="post-list-item"><a class="post-list-link" href="/sublimeIntro/">1.11 sublime text3插件介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/mysqlnotes/">1.13 mysql 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/python_future/">Module篇使用__future__</a></li><li class="post-list-item"><a class="post-list-link" href="/pythonHelp/">Python 帮助文档检索方法</a></li><li class="post-list-item"><a class="post-list-link" href="/tiduxiajiang/">2.5 梯度下降和最小二乘法</a></li><li class="post-list-item"><a class="post-list-link" href="/decisiontree/">2.4 Decision tree</a></li><li class="post-list-item"><a class="post-list-link" href="/webcustomization/">1.10 hexo网页定制</a></li><li class="post-list-item"><a class="post-list-link" href="/hexolocalimage/">1.9 hexo 实现本地图片加载</a></li><li class="post-list-item"><a class="post-list-link" href="/LRN/">2.13 局部响应归一化</a></li><li class="post-list-item"><a class="post-list-link" href="/logisticRe/">2.12 logistic regression</a></li><li class="post-list-item"><a class="post-list-link" href="/pusubeiyesi/">朴素贝叶斯法</a></li><li class="post-list-item"><a class="post-list-link" href="/rosSimulink/">ROS室内仿真环境</a></li><li class="post-list-item"><a class="post-list-link" href="/jidasiranguji/">2.11 极大似然估计</a></li><li class="post-list-item"><a class="post-list-link" href="/yingmaerkefu/">2.1.3 隐马尔科夫HMM</a></li><li class="post-list-item"><a class="post-list-link" href="/PrioritizedEP/">Prioritized Experience Replay</a></li><li class="post-list-item"><a class="post-list-link" href="/shenjingwanguo/">2.7 神经网络浅学笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/zuidashangmoxing/">2.1.2 最大熵模型</a></li><li class="post-list-item"><a class="post-list-link" href="/kjinglin/">K近邻算法</a></li><li class="post-list-item"><a class="post-list-link" href="/diguiyudiedai/">2.6 递归算法与迭代算法</a></li><li class="post-list-item"><a class="post-list-link" href="/xianxinghuigui23/">2.3 线性回归</a></li><li class="post-list-item"><a class="post-list-link" href="/maerkefuyuce/">2.1.1 马尔科夫简单模型预测实战笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/maerkefu21/">2.1 马尔科夫链</a></li><li class="post-list-item"><a class="post-list-link" href="/freelog/">简单的方法，获取在线付费设计log的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/webdessignnotes/">网页设计基础笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/gitIgnore/">Git中忽略提交项</a></li><li class="post-list-item"><a class="post-list-link" href="/matplotlibF/">3.3 matplotlib函数</a></li><li class="post-list-item"><a class="post-list-link" href="/usefullwebsite/">值得收藏的网站</a></li><li class="post-list-item"><a class="post-list-link" href="/stm32chuankou/">STM32串口通信配置（USART1+USART2+USART3+UART4）</a></li><li class="post-list-item"><a class="post-list-link" href="/stm32fuwei/">STM32复位及通过函数判断是何种条件出发的复位</a></li><li class="post-list-item"><a class="post-list-link" href="/tkinternote/">python之tkinter入坑Pack</a></li><li class="post-list-item"><a class="post-list-link" href="/tooold/">故事1：老者病危，不思乡</a></li><li class="post-list-item"><a class="post-list-link" href="/cplusMFC/">C++ MFC 界面实现套接字（socket) 通信</a></li><li class="post-list-item"><a class="post-list-link" href="/hexoHello/">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/vultrFreenom/">vultr+freenom实现主机域名的绑定</a></li><li class="post-list-item"><a class="post-list-link" href="/pytorchNotes/">3.1 PyTorch 学习</a></li><li class="post-list-item"><a class="post-list-link" href="/helloindex/">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/thefirstarticle/">第一篇博文</a></li><li class="post-list-item"><a class="post-list-link" href="/numpyFunc/">3.4 numpy函数</a></li><li class="post-list-item"><a class="post-list-link" href="/DLindex/">第三章 深度学习框架学习</a></li><li class="post-list-item"><a class="post-list-link" href="/hexoDeploy/">Hexo 每次写好后deploy博客</a></li><li class="post-list-item"><a class="post-list-link" href="/sublime_text3/">ubuntu 中安装sublime_text3</a></li><li class="post-list-item"><a class="post-list-link" href="/installplugbychrome/">解决Chrome67版本以后不能离线安装插件的情况</a></li><li class="post-list-item"><a class="post-list-link" href="/searchskill/">搜索技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/gitpush/">git 推送新的文章到github其他分支上</a></li><li class="post-list-item"><a class="post-list-link" href="/fanqiangss/">ubuntu18 正确 安装ShadowSocket</a></li><li class="post-list-item"><a class="post-list-link" href="/pyqttkinter/">python Tkinter 界面实现套接字（socket) 通信</a></li><li class="post-list-item"><a class="post-list-link" href="/DLenviremment/">1.8 深度学习环境搭建</a></li><li class="post-list-item"><a class="post-list-link" href="/gitbookplugset/">1.7 gitbook 插件等相关设置</a></li><li class="post-list-item"><a class="post-list-link" href="/tfComFunction/">3.2 tensorflow1.x常用函数使用</a></li><li class="post-list-item"><a class="post-list-link" href="/pytorchMNIST/">3.1.2 Pytorch 之MNIST手写字识别分类.md</a></li><li class="post-list-item"><a class="post-list-link" href="/doubleSysRepair/">1.6 win10+ubuntu双系统修复ubuntu启动引导</a></li><li class="post-list-item"><a class="post-list-link" href="/tfMNIST/">3.2.1 tensorflow之MNIST</a></li><li class="post-list-item"><a class="post-list-link" href="/linuxcommontool/">1.5 Ubuntu下常用工具软件配置安装</a></li><li class="post-list-item"><a class="post-list-link" href="/latexnotes/">1.4 Latex 排版使用笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/gitcommand/">1.3 Ubuntu18 git命令使用总结</a></li><li class="post-list-item"><a class="post-list-link" href="/installgitbook/">1.2 Ubuntu18安装Gitbook</a></li><li class="post-list-item"><a class="post-list-link" href="/youdaoconf/">1.1 Ubuntu18下有道词典的配置</a></li></ul><!-- rebuild by neat --> <script> </script><!-- rebuild by neat --><!-- rebuild by neat --></div> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><footer id="footer"> <div class="outer"> <div id="footer-info"> <div class="footer-left"> <i class="fa fa-copyright"></i> 2018-2019 Porter Pan </div> <div class="footer-right"> <!--
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a> Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i> //--> <a href="http://hexo.io/" target="_blank" title="Hexo">Hexo</a> Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="hexo-theme-yelee">Yelee</a> by Porter <i class="fa fa-heart animated infinite flash"></i> </div> </div> <div class="visit"> <span id="busuanzi_container_site_pv" style='display:none'> <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span> </span> </span> <span>| </span> <span id="busuanzi_container_page_pv" style='display:none'> <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span> </span> </span> </div> </div> </footer><!-- rebuild by neat --> </div> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><script> $(document).ready(function() { var iPad = window.navigator.userAgent.indexOf('iPad'); if (iPad > -1 || $(".left-col").css("display") === "none") { var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"]; var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1)); $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"}); } else { var backgroundnum = 5; var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum)); $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"}); } }) </script><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><!-- Google Analytics --> <script type="text/javascript"> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-132871432-3', 'auto'); ga('send', 'pageview'); </script> <!-- End Google Analytics --><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] } }); MathJax.Hub.Queue(function() { var all = MathJax.Hub.getAllJax(), i; for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script> <script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><div class="scroll" id="scroll"> <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a> <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a> <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a> </div><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><script> // Open in New Window var oOpenInNew = { archives: ".archive-article-title", miniArchives: "a.post-list-link", menu: ".header-menu a", friends: "#js-friends a", socail: ".social a" } for (var x in oOpenInNew) { $(oOpenInNew[x]).attr("target", "_blank"); } </script><!-- rebuild by neat --> <!-- build time:Mon Nov 18 2019 20:42:35 GMT+0800 (GMT+08:00) --><!-- rebuild by neat --> <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"> </script><!-- rebuild by neat --> </div> </body> </html><!-- rebuild by neat -->